#!/usr/bin/env bash

#ensures there are no accidental downloads
set -eo pipefail

baseurl="https://www.1377x.to/"
cachedir="$HOME/.cache/dl"

#get query from dmenu(later rofi)
query=$(echo "" | rofi -dmenu -p "Search Torrent" | sed 's/ /+/g')

#setup working dir
mkdir -p $cachedir
cd $cachedir

curl -s $baseurl/search/$query/1/ -o tmp.html


#get titles
grep -o '<a href=./torrent/.*</a>' tmp.html |
	sed 's/<[^>]*>//g' > titles.bw #deletes tags
#get seeders
grep -P '<td class="coll-2 seeds">\d*</td>' tmp.html |
	sed 's/<[^>]*>//g' > seeders.bw
#get leechers
grep -P '<td class="coll-3 leeches">\d*</td>' tmp.html |
	sed 's/<[^>]*>//g' > leechers.bw
#get sizes
grep -P '<td class="coll-4 size mob-uploader">.*</td>' tmp.html |
	sed 's/<[^>]*>//g' > sizes.bw
#get links 
grep -E '/torrent/' tmp.html |
	sed -E 's#.*(/torrent/.*)/">.*/#\1#' |
	sed 's/td>//g' > links.bw

#generates line numbers
awk '{print NR " - "$0""}' titles.bw > titlesNumbered.bw

#gets line number (that groupthe user selected in dmenu)
LINE=$(paste -d\| titlesNumbered.bw seeders.bw leechers.bw sizes.bw |
   	rofi -dmenu -i -l 25 |
   	cut -d- -f1
)

suburl=$(sed "${LINE}q;d" links.bw)
url="$baseurl$suburl/"

#get page that contains magnet link
curl -s $url > tmp.html

#scrape magnet link
magnet=$(paste tmp.html |
	tr -d '\n' |
	sed -E 's#.*(magnet:\?xt=urn:btih:[^"]*).*#\1#'
)

deluge-console add $magnet

#notify the user that the download has started
notify-send "⬇️ download started ⬇️"
